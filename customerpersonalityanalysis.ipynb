{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-01T18:26:28.578131Z","iopub.execute_input":"2022-02-01T18:26:28.578455Z","iopub.status.idle":"2022-02-01T18:26:28.590598Z","shell.execute_reply.started":"2022-02-01T18:26:28.578412Z","shell.execute_reply":"2022-02-01T18:26:28.589668Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"pip install scikit-learn-extra","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:28.592466Z","iopub.execute_input":"2022-02-01T18:26:28.592898Z","iopub.status.idle":"2022-02-01T18:26:37.983328Z","shell.execute_reply.started":"2022-02-01T18:26:28.592863Z","shell.execute_reply":"2022-02-01T18:26:37.982093Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"pip install pyclustering\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:37.985103Z","iopub.execute_input":"2022-02-01T18:26:37.985359Z","iopub.status.idle":"2022-02-01T18:26:47.390388Z","shell.execute_reply.started":"2022-02-01T18:26:37.985328Z","shell.execute_reply":"2022-02-01T18:26:47.389273Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import Birch\nfrom sklearn_extra.cluster import KMedoids\nfrom sklearn.cluster import AffinityPropagation\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import KernelPCA\nfrom sklearn.metrics import silhouette_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.393175Z","iopub.execute_input":"2022-02-01T18:26:47.393417Z","iopub.status.idle":"2022-02-01T18:26:47.399922Z","shell.execute_reply.started":"2022-02-01T18:26:47.393387Z","shell.execute_reply":"2022-02-01T18:26:47.398765Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing\nThe objective is to first broadly understand the data infront of us with regards to statistical properties and features","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/customer-personality-analysis/marketing_campaign.csv',sep=\"\\t\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.401538Z","iopub.execute_input":"2022-02-01T18:26:47.401905Z","iopub.status.idle":"2022-02-01T18:26:47.447407Z","shell.execute_reply.started":"2022-02-01T18:26:47.401869Z","shell.execute_reply":"2022-02-01T18:26:47.446750Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.448296Z","iopub.execute_input":"2022-02-01T18:26:47.448529Z","iopub.status.idle":"2022-02-01T18:26:47.466268Z","shell.execute_reply.started":"2022-02-01T18:26:47.448500Z","shell.execute_reply":"2022-02-01T18:26:47.465148Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.467172Z","iopub.execute_input":"2022-02-01T18:26:47.467393Z","iopub.status.idle":"2022-02-01T18:26:47.558266Z","shell.execute_reply.started":"2022-02-01T18:26:47.467363Z","shell.execute_reply":"2022-02-01T18:26:47.557215Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"From the dataset description, it is evident that the following two columns do not correspond to any significant information for further analysis and therefore, it can be conveniently dropped","metadata":{}},{"cell_type":"code","source":"df.drop(['Z_CostContact', 'Z_Revenue'], axis=1, inplace=True)\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.560058Z","iopub.execute_input":"2022-02-01T18:26:47.560438Z","iopub.status.idle":"2022-02-01T18:26:47.569199Z","shell.execute_reply.started":"2022-02-01T18:26:47.560392Z","shell.execute_reply":"2022-02-01T18:26:47.568160Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"# Handling null values\nFrom the above information, it is clear that only the income column has some null values, and since their number is not very high, we can replace them by the median income value","metadata":{}},{"cell_type":"code","source":"df['Income'] = df['Income'].fillna(df['Income'].median())\ndf.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.572127Z","iopub.execute_input":"2022-02-01T18:26:47.572392Z","iopub.status.idle":"2022-02-01T18:26:47.587777Z","shell.execute_reply.started":"2022-02-01T18:26:47.572360Z","shell.execute_reply":"2022-02-01T18:26:47.586738Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering\n* A column for age is prepared using the date of birth of each customer\n* The food expenditure is combined for meat and fish products to form a non-veg column and the remaining are combined as a different column\n* The marital status column is encoded to numerical value\n* The number of kids and teens are combined to form the total number of children for a family","metadata":{}},{"cell_type":"code","source":"df['Age'] = 2022 - df['Year_Birth']\ndf['Non_Veg_Amt']= df['MntMeatProducts'] + df['MntFishProducts']\ndf['Others_Amt'] = df['MntWines'] + df['MntSweetProducts'] + df['MntFruits']\ndf.drop(['MntMeatProducts', 'MntFishProducts', 'MntWines','MntSweetProducts', 'MntFruits'], axis=1, inplace=True)\ndf.drop('Year_Birth', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.589183Z","iopub.execute_input":"2022-02-01T18:26:47.589767Z","iopub.status.idle":"2022-02-01T18:26:47.604740Z","shell.execute_reply.started":"2022-02-01T18:26:47.589642Z","shell.execute_reply":"2022-02-01T18:26:47.604004Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"df['Education'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.606150Z","iopub.execute_input":"2022-02-01T18:26:47.606567Z","iopub.status.idle":"2022-02-01T18:26:47.617075Z","shell.execute_reply.started":"2022-02-01T18:26:47.606536Z","shell.execute_reply":"2022-02-01T18:26:47.616039Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"df['Marital_Status'].value_counts() ","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.618783Z","iopub.execute_input":"2022-02-01T18:26:47.619403Z","iopub.status.idle":"2022-02-01T18:26:47.628023Z","shell.execute_reply.started":"2022-02-01T18:26:47.619355Z","shell.execute_reply":"2022-02-01T18:26:47.627075Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"df['Children'] = df['Kidhome']+df['Teenhome']\ndf['Family_Size'] = df['Children'] + df['Marital_Status'].replace({'Married':2, 'Together':2, 'Single':1, 'Divorced':1, 'Widow':1,\n                                                                  'Alone':1, 'Absurd':1,'YOLO':1})\ndf.drop(['Kidhome','Teenhome'], axis=1, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.629262Z","iopub.execute_input":"2022-02-01T18:26:47.630199Z","iopub.status.idle":"2022-02-01T18:26:47.646090Z","shell.execute_reply.started":"2022-02-01T18:26:47.630152Z","shell.execute_reply":"2022-02-01T18:26:47.645161Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"df['Marital_Status'].replace({'Married':2, 'Together':2, 'Single':1, 'Divorced':1, 'Widow':1,\n                                                                  'Alone':1, 'Absurd':1,'YOLO':1}, inplace=True)\ndf['Marital_Status'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.647237Z","iopub.execute_input":"2022-02-01T18:26:47.647749Z","iopub.status.idle":"2022-02-01T18:26:47.662242Z","shell.execute_reply.started":"2022-02-01T18:26:47.647704Z","shell.execute_reply":"2022-02-01T18:26:47.661220Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory data analysis\nThe objective here is to have a holistic understanding of the customer base in the market through specific queries. Athough, the dataset has several features, it can be understood that certain features like complain, acceptance of ad campaign have a particular significance behind this customer analysis study.","metadata":{}},{"cell_type":"markdown","source":"# How many people accepted the offer in each campaign?\nThrough this question, we can understand how successful each of the ad campaing has been with regards to customer acceptance","metadata":{}},{"cell_type":"code","source":"camp_lst = ['AcceptedCmp1', 'AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5','Response']\nval_lst = []\nfor elm in camp_lst:\n    cond = df[elm]==1\n    val_lst.append(df.loc[cond, elm].count())\n    \nfig = plt.figure(figsize =(10, 10)) \nplt.bar(camp_lst, val_lst, color ='lightgreen',\n        width = 0.4)\nplt.grid(zorder = 0, axis = \"y\")\nplt.xlabel(\"Campaign rounds\", fontsize = 18, labelpad=15)\nplt.xticks(rotation=90)\nplt.ylabel(\"No. of customers\",fontsize = 18, labelpad=15)\nplt.title(\"No. of customers accepting the campaign\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.663932Z","iopub.execute_input":"2022-02-01T18:26:47.664355Z","iopub.status.idle":"2022-02-01T18:26:47.921351Z","shell.execute_reply.started":"2022-02-01T18:26:47.664305Z","shell.execute_reply":"2022-02-01T18:26:47.920653Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"# How many single and married customers accepted the offer in each campaign?","metadata":{}},{"cell_type":"code","source":"cond1 = df['Marital_Status']==1\ncond2 = df['Marital_Status']==2\ncond3 = df['AcceptedCmp1'] == 1\n\ndf.loc[(cond1) &(cond3)].shape[0]\n\nsing_lst = []\nmarr_lst = []\nc1 = df['Marital_Status']==1\nc2 = df['Marital_Status']==2\nfor elm in camp_lst:\n    c3 = df[elm]==1\n    sing_lst.append(df.loc[(c1)& (c3)].shape[0])\n    marr_lst.append(df.loc[(c2)&(c3)].shape[0])\n    \nX_axis = np.arange(len(camp_lst)) \nfig = plt.figure(figsize =(10, 10)) \nplt.bar(X_axis - 0.2, sing_lst, 0.4, color = 'lightblue',label = 'Single')\nplt.bar(X_axis + 0.2, marr_lst, 0.4, label = 'Married')\nplt.grid(zorder = 0, axis = \"y\")  \nplt.xticks(X_axis, camp_lst)\nplt.xlabel(\"Customer group\",fontsize = 18, labelpad=15)\nplt.ylabel(\"Number of customers\", fontsize = 18, labelpad=15)\nplt.title(\"Number of customers accepting offer in each campaign\", fontsize = 18)\nplt.xticks(rotation=90)\nplt.legend()\nplt.show()\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:47.922638Z","iopub.execute_input":"2022-02-01T18:26:47.923062Z","iopub.status.idle":"2022-02-01T18:26:48.268428Z","shell.execute_reply.started":"2022-02-01T18:26:47.923011Z","shell.execute_reply":"2022-02-01T18:26:48.267661Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"# How many customers who have complained atleast once in last two years have accepted the campaign offer?","metadata":{}},{"cell_type":"code","source":"df['Complain'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:48.269753Z","iopub.execute_input":"2022-02-01T18:26:48.270165Z","iopub.status.idle":"2022-02-01T18:26:48.278284Z","shell.execute_reply.started":"2022-02-01T18:26:48.270115Z","shell.execute_reply":"2022-02-01T18:26:48.277057Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"compln_yes = []\ncompln_no = []\nc1 = df['Complain']==1\nc2 = df['Complain']==0\nfor elm in camp_lst:\n    c3 = df[elm]==1\n    compln_yes.append(df.loc[(c1)& (c3)].shape[0])\n    compln_no.append(df.loc[(c2)&(c3)].shape[0])\n    \nX_axis = np.arange(len(camp_lst)) \nfig = plt.figure(figsize =(10, 10))\nplt.bar(X_axis - 0.2, compln_yes, 0.4,label = 'Complained in two years')\nplt.bar(X_axis + 0.2, compln_no, 0.4, label = 'Not complained')\nplt.grid(zorder = 0, axis = \"y\")  \nplt.xticks(X_axis, camp_lst)\nplt.xlabel(\"Campaign\",fontsize = 18, labelpad=15)\nplt.ylabel(\"Number of customers\", fontsize = 18, labelpad=15)\nplt.title(\"Number of customers accepting offer in each campaign\")\nplt.xticks(rotation=90)\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:48.279743Z","iopub.execute_input":"2022-02-01T18:26:48.279991Z","iopub.status.idle":"2022-02-01T18:26:48.542885Z","shell.execute_reply.started":"2022-02-01T18:26:48.279958Z","shell.execute_reply":"2022-02-01T18:26:48.542001Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"# What is the total expenditure in each food category of customers accepting campaign offer?","metadata":{}},{"cell_type":"code","source":"NonVeg = []\nOther = []\nGold = []\nfor elm in camp_lst:\n    c1 = df[elm]==1\n    NonVeg.append(df[c1]['Non_Veg_Amt'].sum())\n    Other.append(df[c1]['Others_Amt'].sum())\n    Gold.append(df[c1]['MntGoldProds'].sum())\n\nX_axis = np.arange(len(camp_lst)) \nwidth = 0.25\nfig = plt.figure(figsize =(10, 10))\nbar1 = plt.bar(X_axis, NonVeg, width, color = 'violet')\nbar2 = plt.bar(X_axis+width, Other, width, color = 'skyblue')\nbar3 = plt.bar(X_axis+width*2, Gold, width, color = 'yellow')\nplt.xticks(X_axis, camp_lst)\nplt.grid(zorder = 0, axis = \"y\")\nplt.xlabel(\"Campaign\", fontsize = 18, labelpad=15)\nplt.ylabel(\"Amount spent by customers\", fontsize = 18, labelpad=15)\nplt.title(\"Amount spent in each food category of people accepting campaign offers\")\nplt.xticks(rotation=90)\nplt.legend((bar1,bar2,bar3), ('Non veg amount', \"Others\", 'Gold amount'))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:48.544686Z","iopub.execute_input":"2022-02-01T18:26:48.545063Z","iopub.status.idle":"2022-02-01T18:26:48.843950Z","shell.execute_reply.started":"2022-02-01T18:26:48.545016Z","shell.execute_reply":"2022-02-01T18:26:48.843047Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"df[cond]['Education'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:48.845145Z","iopub.execute_input":"2022-02-01T18:26:48.845396Z","iopub.status.idle":"2022-02-01T18:26:48.854572Z","shell.execute_reply.started":"2022-02-01T18:26:48.845365Z","shell.execute_reply":"2022-02-01T18:26:48.853752Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"cond = df['Complain']==1\nx = df[cond]['Education'].value_counts()\nexplode = (0.1,0.1,0,0,)\nfig, ax = plt.subplots()\nlabels = 'Graduation', '2n Cycle', 'Master', 'PhD'\nax.pie( x, labels = labels, explode= explode,radius =2, textprops={'fontsize': 16}, autopct='%1.1f%%')\nplt.suptitle(\"Education level of customers who have complained\", size =20, y=1.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:48.855826Z","iopub.execute_input":"2022-02-01T18:26:48.856117Z","iopub.status.idle":"2022-02-01T18:26:49.168007Z","shell.execute_reply.started":"2022-02-01T18:26:48.856081Z","shell.execute_reply":"2022-02-01T18:26:49.166695Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"x = df[cond]['Children'].value_counts()\nexplode = (0.1,0.1,0,0,)\nfig, ax = plt.subplots()\nlabels = '1', '2', '0', '3'\nax.pie( x, labels = labels, explode= explode,radius =2, textprops={'fontsize': 16}, autopct='%1.1f%%')\nplt.suptitle(\"Distribution of no. of children amonf customers who have complained\", size =20, y=1.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:49.169606Z","iopub.execute_input":"2022-02-01T18:26:49.170248Z","iopub.status.idle":"2022-02-01T18:26:49.309865Z","shell.execute_reply.started":"2022-02-01T18:26:49.170199Z","shell.execute_reply":"2022-02-01T18:26:49.308712Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"# Customers who have accepted offer in multiple ad campaign","metadata":{}},{"cell_type":"markdown","source":"# How many customers who have purchased with deals have accepted the campaign offers?","metadata":{}},{"cell_type":"code","source":"val = []\nc2 = df['NumDealsPurchases'] != 0\nfor elm in camp_lst:\n    cond = df[elm]==1\n    val.append(df[cond][c2].shape[0])\n  ","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:49.311760Z","iopub.execute_input":"2022-02-01T18:26:49.312850Z","iopub.status.idle":"2022-02-01T18:26:49.331051Z","shell.execute_reply.started":"2022-02-01T18:26:49.312798Z","shell.execute_reply":"2022-02-01T18:26:49.329375Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize =(10, 10)) \nplt.bar(camp_lst, val, color ='limegreen',\n        width = 0.4)\nplt.grid(zorder = 0, axis = \"y\")\nplt.xlabel(\"Campaign rounds\", fontsize = 18, labelpad=15)\nplt.xticks(rotation=90)\nplt.ylabel(\"No. of customers\",fontsize = 18, labelpad=15)\nplt.title(\"No. of customers buying with deals accepting the campaign\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:49.336579Z","iopub.execute_input":"2022-02-01T18:26:49.337539Z","iopub.status.idle":"2022-02-01T18:26:49.600495Z","shell.execute_reply.started":"2022-02-01T18:26:49.337478Z","shell.execute_reply":"2022-02-01T18:26:49.599760Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"df.drop('Dt_Customer',axis=1, inplace=True)\ndf.drop('ID', axis=1, inplace=True)\ndf = pd.get_dummies(df, columns=['Education'])\ndf.drop('Education_Basic', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:49.601592Z","iopub.execute_input":"2022-02-01T18:26:49.601960Z","iopub.status.idle":"2022-02-01T18:26:49.613290Z","shell.execute_reply.started":"2022-02-01T18:26:49.601930Z","shell.execute_reply":"2022-02-01T18:26:49.612663Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"# Handling outliers\nFrom the boxplot below, it is evident that there are outliers for several numerical features. Since, our dataset is not very large, we replace the outlier values using the interquartile-range method.","metadata":{}},{"cell_type":"code","source":"cols = ['Age','Income', 'MntGoldProds', 'Non_Veg_Amt', 'Others_Amt']\nfor fea in cols:\n    plt.figure(figsize=(8,8))\n    sns.boxplot(df[fea])\n    plt.title(fea, fontsize=20)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:49.614366Z","iopub.execute_input":"2022-02-01T18:26:49.614725Z","iopub.status.idle":"2022-02-01T18:26:50.561605Z","shell.execute_reply.started":"2022-02-01T18:26:49.614694Z","shell.execute_reply":"2022-02-01T18:26:50.560649Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"cols = ['Age','Income', 'MntGoldProds', 'Non_Veg_Amt', 'Others_Amt']\nfor elm in cols:\n    q1 = df[elm].quantile(0.25)\n    q3 =  df[elm].quantile(0.75)\n    iqr = q3 - q1\n    up_lim = q3 +1.5*iqr\n    low_lim = q1 - 1.5*iqr\n    cond = df[elm] > up_lim\n    df.loc[cond, elm]= up_lim\n    \nfor fea in cols:\n    plt.figure(figsize=(8,8))\n    sns.boxplot(df[fea])\n    plt.title(fea, fontsize=20)\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:50.563146Z","iopub.execute_input":"2022-02-01T18:26:50.564085Z","iopub.status.idle":"2022-02-01T18:26:51.523121Z","shell.execute_reply.started":"2022-02-01T18:26:50.564047Z","shell.execute_reply":"2022-02-01T18:26:51.522085Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"# Feature scaling\nNow that we have done an exhaustive analysis of the data and preprocessing,we can move towards model implementation. However, we also have to do appropriate scaling of our features in order to have better efficiency.","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\ndf_sc = scaler.fit_transform(df)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:51.524259Z","iopub.execute_input":"2022-02-01T18:26:51.524503Z","iopub.status.idle":"2022-02-01T18:26:51.537975Z","shell.execute_reply.started":"2022-02-01T18:26:51.524472Z","shell.execute_reply":"2022-02-01T18:26:51.536539Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"# Model implementation for cluster analysis\n* Since the dataset has a large number of features, we intend to apply PCA and perform clustering analysis in two dimension\n* Perform elbow method to determine the ideal number of clusters\n* We experiment with multiple algorithms to gain a broad overview of the performance\n","metadata":{}},{"cell_type":"code","source":"pca = KernelPCA(n_components=2, gamma=0.0433, fit_inverse_transform=True)\nreduced= pca.fit_transform(df_sc)\ndf_pca = pd.DataFrame(reduced)\ninv_trns = pca.inverse_transform(reduced)\n\nfrom sklearn.metrics import mean_squared_error\nprint('mean_squared_error of original dataset and inverse transformed dataset reduced by kernel PCA {:.2e}'.format(mean_squared_error(df_sc, inv_trns)))","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:51.539831Z","iopub.execute_input":"2022-02-01T18:26:51.540544Z","iopub.status.idle":"2022-02-01T18:26:52.315685Z","shell.execute_reply.started":"2022-02-01T18:26:51.540490Z","shell.execute_reply":"2022-02-01T18:26:52.314575Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"wcss = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(df_pca) \n    wcss.append(kmeans.inertia_)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:52.321437Z","iopub.execute_input":"2022-02-01T18:26:52.324488Z","iopub.status.idle":"2022-02-01T18:26:53.784798Z","shell.execute_reply.started":"2022-02-01T18:26:52.324423Z","shell.execute_reply":"2022-02-01T18:26:53.783862Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(1, 11), wcss)\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS') \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:53.786276Z","iopub.execute_input":"2022-02-01T18:26:53.786553Z","iopub.status.idle":"2022-02-01T18:26:54.014247Z","shell.execute_reply.started":"2022-02-01T18:26:53.786515Z","shell.execute_reply":"2022-02-01T18:26:54.013308Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"From the above figure, it seems that the optimal number of clusters applicable isthree, but four seems equally plausible. As such we can test our model performace for both three and four clusters","metadata":{}},{"cell_type":"markdown","source":"# K-Means","metadata":{}},{"cell_type":"code","source":"df_dum = df_pca.copy()\nfor k in range(3,5):\n    kmeans = KMeans(n_clusters=k)\n    df_dum['Cluster Number',k] = kmeans.fit_predict(df_dum)\n    val_coun = df_dum['Cluster Number',k].value_counts()\n    print('Cluster distribution with ',k, 'clusters')\n    print(val_coun)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:54.016075Z","iopub.execute_input":"2022-02-01T18:26:54.016716Z","iopub.status.idle":"2022-02-01T18:26:54.226765Z","shell.execute_reply.started":"2022-02-01T18:26:54.016651Z","shell.execute_reply":"2022-02-01T18:26:54.225753Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"# K-Medoids","metadata":{}},{"cell_type":"code","source":"df_dum = df_pca.copy()\nfor k in range(3,5):\n    kmeds = KMedoids(n_clusters=k)\n    df_dum['Cluster Number',k] = kmeds.fit_predict(df_dum)\n    val_coun = df_dum['Cluster Number',k].value_counts()\n    print('Cluster distribution with ',k, 'clusters')\n    print(val_coun)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:54.228633Z","iopub.execute_input":"2022-02-01T18:26:54.229290Z","iopub.status.idle":"2022-02-01T18:26:55.252567Z","shell.execute_reply.started":"2022-02-01T18:26:54.229227Z","shell.execute_reply":"2022-02-01T18:26:55.251526Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"# BIRCH","metadata":{}},{"cell_type":"code","source":"df_dum = df_pca.copy()\nfor k in range(3,5):\n    birch = Birch(n_clusters=k)\n    df_dum['Cluster Number',k] = birch.fit_predict(df_dum)\n    val_coun = df_dum['Cluster Number',k].value_counts()\n    print('Cluster distribution with ',k, 'clusters')\n    print(val_coun)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:55.254019Z","iopub.execute_input":"2022-02-01T18:26:55.254259Z","iopub.status.idle":"2022-02-01T18:26:55.585905Z","shell.execute_reply.started":"2022-02-01T18:26:55.254227Z","shell.execute_reply":"2022-02-01T18:26:55.584804Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"# Agglomerative Clustering","metadata":{}},{"cell_type":"code","source":"df_dum = df_pca.copy()\nfor k in range(3,5):\n    clr = AgglomerativeClustering(n_clusters=k)\n    df_dum['Cluster Number',k] = clr.fit_predict(df_dum)\n    val_coun = df_dum['Cluster Number',k].value_counts()\n    print('Cluster distribution with ',k, 'clusters')\n    print(val_coun)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:55.587860Z","iopub.execute_input":"2022-02-01T18:26:55.588378Z","iopub.status.idle":"2022-02-01T18:26:55.906909Z","shell.execute_reply.started":"2022-02-01T18:26:55.588329Z","shell.execute_reply":"2022-02-01T18:26:55.905828Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"# Model evaluation\n* We consider the silhouette score as the performance metric and attempt to obtain the best combination of hyperparameter values \n* The cluster distribution for a range of models is obtained in a 2D plot","metadata":{}},{"cell_type":"code","source":"s = []\nmax_s = 0\nmax_s_n_clusters = None\naffinity = ['euclidean', 'l1','l2', 'cosine','manhattan']\nlinkage = ['complete','average','single']\nbest_aff = None\nbest_l = None\nfor aff in affinity:\n    for l in linkage:\n        for i in np.arange(2,8):\n            hierarchical_cl = AgglomerativeClustering(n_clusters=i, affinity= aff, linkage = l)\n            ypred = hierarchical_cl.fit_predict(reduced)\n            sil = silhouette_score(reduced, ypred)\n            if sil > max_s:\n                max_s = sil\n                max_s_n_clusters = np.unique(ypred)\n                best_aff = aff\n                best_l = l\n\nprint('Maximal silhoutte {:.3f}'.format(max_s))\nprint('Optimal number of clusters', len(max_s_n_clusters))\nprint('Optimal affinity', best_aff)\nprint('Optimal linkage', best_l)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:26:55.909962Z","iopub.execute_input":"2022-02-01T18:26:55.910192Z","iopub.status.idle":"2022-02-01T18:27:17.084498Z","shell.execute_reply.started":"2022-02-01T18:26:55.910161Z","shell.execute_reply":"2022-02-01T18:27:17.083741Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"# Visualization of cluster formation","metadata":{}},{"cell_type":"code","source":"df_pred = df_pca.copy()\n\ndf_pred['Cluster Number (AC)'] = AgglomerativeClustering(n_clusters=4).fit_predict(df_pca)\ndf_pred['Cluster Number (KM)'] = KMeans(n_clusters=4).fit_predict(df_pca)\ndf_pred['Cluster Number (KMed)'] = KMedoids(n_clusters = 4).fit_predict(df_pca)\ndf_pred['Cluster Number (BRC)'] = Birch(n_clusters = 4).fit_predict(df_pca)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:29:13.872175Z","iopub.execute_input":"2022-02-01T18:29:13.872508Z","iopub.status.idle":"2022-02-01T18:29:14.763140Z","shell.execute_reply.started":"2022-02-01T18:29:13.872474Z","shell.execute_reply":"2022-02-01T18:29:14.761778Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nax = plt.subplot(111, label=\"bl2\")\nax.scatter(x = df_pca[0], y=df_pca[1], s=40,c = df_pred['Cluster Number (KM)'],marker='o' )\nax.set_title(\"Cluster distribution in KMeans clustering \")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:29:22.421845Z","iopub.execute_input":"2022-02-01T18:29:22.422127Z","iopub.status.idle":"2022-02-01T18:29:22.713888Z","shell.execute_reply.started":"2022-02-01T18:29:22.422094Z","shell.execute_reply":"2022-02-01T18:29:22.712935Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nax = plt.subplot(111, label=\"bl2\")\nax.scatter(x = df_pca[0], y=df_pca[1], s=40,c = df_pred['Cluster Number (KMed)'],marker='o' )\nax.set_title(\"Cluster distribution in KMedoids clustering \")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:30:57.294360Z","iopub.execute_input":"2022-02-01T18:30:57.294693Z","iopub.status.idle":"2022-02-01T18:30:57.592409Z","shell.execute_reply.started":"2022-02-01T18:30:57.294637Z","shell.execute_reply":"2022-02-01T18:30:57.591731Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nax = plt.subplot(111, label=\"bl2\")\nax.scatter(x = df_pca[0], y=df_pca[1], s=40,c = df_pred['Cluster Number (BRC)'],marker='o' )\nax.set_title(\"Cluster distribution in BIRCH clustering \")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:31:13.118919Z","iopub.execute_input":"2022-02-01T18:31:13.119461Z","iopub.status.idle":"2022-02-01T18:31:13.412085Z","shell.execute_reply.started":"2022-02-01T18:31:13.119408Z","shell.execute_reply":"2022-02-01T18:31:13.411413Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nax = plt.subplot(111, label=\"bl2\")\nax.scatter(x = df_pca[0], y=df_pca[1], s=40,c = df_pred['Cluster Number (AC)'],marker='o' )\nax.set_title(\"Cluster distribution in Agglomerative clustering \")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-01T18:31:31.356363Z","iopub.execute_input":"2022-02-01T18:31:31.356816Z","iopub.status.idle":"2022-02-01T18:31:31.651620Z","shell.execute_reply.started":"2022-02-01T18:31:31.356780Z","shell.execute_reply":"2022-02-01T18:31:31.650600Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}